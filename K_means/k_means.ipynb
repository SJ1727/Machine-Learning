{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PCA.pca import calculate_principal_components, project_onto_components\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "INF = sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our dataset using pandas\n",
    "df = pd.read_csv(\"../data/iris.csv\")\n",
    "\n",
    "# Splitting data\n",
    "outcomes = np.array(df[\"species\"].map({species: i for i, species in enumerate(df[\"species\"].unique())}))\n",
    "data = np.array(df.drop([\"species\"], axis=1).values)\n",
    "\n",
    "# Normilizing data\n",
    "data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "\n",
    "print(f\"Mean of each column: {np.mean(data, axis=0)}\\n\")\n",
    "print(f\"Standard deviation of each column: {np.std(data, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(data, k, iterations=1):\n",
    "    best_clustering = None\n",
    "    best_clustering_variance = INF\n",
    "    previous_cluster_classifications = None\n",
    "    current_cluster_classifications = np.zeros(data.shape[0])\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Select random points\n",
    "        current_clustering = np.array([[\n",
    "            np.random.uniform(np.min(row), np.max(row)) for row in data.T\n",
    "        ] for _ in range(k)])\n",
    "\n",
    "        # Classify the data points based on the closest cluster\n",
    "        for i, data_point in enumerate(data):\n",
    "            current_cluster_classifications[i] = np.argmin([np.linalg.norm(data_point - cluster) for cluster in current_clustering])\n",
    "\n",
    "        # Keep moving the clusters to the mean of the clusters until the classifications dont change any more\n",
    "        while (previous_cluster_classifications != current_cluster_classifications).any():\n",
    "            previous_cluster_classifications = current_cluster_classifications.copy()\n",
    "\n",
    "            # Moving the clusters to the mean of the clusters\n",
    "            current_clustering = np.array([\n",
    "                np.nan_to_num(np.nanmean(\n",
    "                    data[np.where(current_cluster_classifications == i)],\n",
    "                    axis=0,\n",
    "                ), nan=0)\n",
    "            for i in range(k)])\n",
    "            \n",
    "            # Classify the data points based on the closest cluster\n",
    "            for i, data_point in enumerate(data):\n",
    "                current_cluster_classifications[i] = np.argmin([np.linalg.norm(data_point - cluster) for cluster in current_clustering])\n",
    "\n",
    "        # Calculate the variance of the cluster classifications\n",
    "        current_variance = np.sum(\n",
    "            [np.var(data[np.where(current_cluster_classifications == i)] if len(np.where(current_cluster_classifications == i)) != 0 else INF)\n",
    "        for i in range(k)])\n",
    "\n",
    "        # Replace the current best clustering if the new cluster has a lower variance\n",
    "        if current_variance < best_clustering_variance:\n",
    "            best_clustering = current_clustering\n",
    "            best_clustering_variance = current_variance\n",
    "\n",
    "    return best_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_cluster(data, clusters):\n",
    "    return np.array([\n",
    "        np.argmin([np.linalg.norm(data_point - cluster) for cluster in clusters]) for data_point in data\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = k_means(data, 3, iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components, _ = calculate_principal_components(data, components=2)\n",
    "cluster_classifications = closest_cluster(data, cluster_centers)\n",
    "projected_data = project_onto_components(data, components)\n",
    "projected_cluster_centers = project_onto_components(cluster_centers, components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(f\"Principal Component 1\")\n",
    "plt.ylabel(f\"Principal Component 2\")\n",
    "plt.scatter(projected_data[:, 0], projected_data[:, 1], c=cluster_classifications, s=3)\n",
    "plt.scatter(projected_cluster_centers[:, 0], projected_cluster_centers[:, 1], c=\"#00FF00\", s=15)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
